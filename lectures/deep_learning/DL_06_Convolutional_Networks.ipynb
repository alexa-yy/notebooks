{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/DL.png\" width=110 align=\"left\" style=\"margin-right: 10px\">\n",
    "\n",
    "# Introduction to Deep Learning\n",
    "\n",
    "## 06. Convolutional Networks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Convolutional Neural Network (CNN)](https://keras.io/layers/convolutional/)\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png\" width=600 alt=\"Typical cnn.png\"><br>By <a href=\"//commons.wikimedia.org/w/index.php?title=User:Aphex34&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"User:Aphex34 (page does not exist)\">Aphex34</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=45679374\">Link</a>\n",
    "\n",
    "> _Convolutional Neural Networks are very similar to ordinary Neural Networks: they are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer and all the tips/tricks we developed for learning regular Neural Networks still apply._  \n",
    " _So what changes? ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network._ - [source](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "> _Convolutional Neural Networks have a different architecture than regular Neural Networks. Regular Neural Networks transform an input by putting it through a series of hidden layers. Every layer is made up of a set of neurons, where each layer is fully connected to all neurons in the layer before. Finally, there is a last fully-connected layer — the output layer — that represent the predictions._  \n",
    " _Convolutional Neural Networks are a bit different. First of all, the layers are organised in 3 dimensions: width, height and depth. Further, the neurons in one layer do not connect to all the neurons in the next layer but only to a small region of it. Lastly, the final output will be reduced to a single vector of probability scores, organized along the depth dimension._ - [source](https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050)\n",
    "\n",
    "A Convolutional Neural Network consists of different building blocks:\n",
    "- Convolutional layers: feature extraction\n",
    "- Pooling layers: feature selection\n",
    "- Dense layers: classification\n",
    "\n",
    "#### Convolution layer\n",
    "\n",
    "A filtering layer with a learnable filter. It's purpose is to detect features in the input. In case of images these features could be edges, or even shapes. \n",
    "\n",
    "> _In mathematics convolution is a mathematical operation on two functions (f and g) to produce a third function that expresses how the shape of one is modified by the other._ - [source](https://en.wikipedia.org/wiki/Convolution)\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/6a/Convolution_of_box_signal_with_itself2.gif\" alt=\"Convolution of box signal with itself2.gif\"><br>By <a href=\"//commons.wikimedia.org/wiki/File:Convolution_of_box_signal_with_itself.gif\" title=\"File:Convolution of box signal with itself.gif\">Convolution_of_box_signal_with_itself.gif</a>: Brian Amberg\n",
    "derivative work: <a href=\"//commons.wikimedia.org/wiki/User:Tinos\" title=\"User:Tinos\">Tinos</a> (<a href=\"//commons.wikimedia.org/wiki/User_talk:Tinos\" title=\"User talk:Tinos\"><span class=\"signature-talk\">talk</span></a>) - <a href=\"//commons.wikimedia.org/wiki/File:Convolution_of_box_signal_with_itself.gif\" title=\"File:Convolution of box signal with itself.gif\">Convolution_of_box_signal_with_itself.gif</a>, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\" title=\"Creative Commons Attribution-Share Alike 3.0\">CC BY-SA 3.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=11003835\">Link</a></p>\n",
    "\n",
    "> _We execute a convolution by sliding the filter over the input. At every location, a matrix multiplication is performed and sums the result onto the feature map._ \n",
    "_In the animation below, you can see the convolution operation. You can see the filter (the green square) is sliding over our input (the blue square) and the sum of the convolution goes into the feature map (the red square)._ - [source](https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050)\n",
    "\n",
    "<div style=\"display: inline-block;\">\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif\" width=400 align='left'>\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*EuSjHyyDRPAQUdKCKLTgIQ.png\" width=400 align='left'>\n",
    "</div>\n",
    "\n",
    "<div style='align: clear'>\n",
    "<br>\n",
    "Animation by <a href=\"https://towardsdatascience.com/@ardendertat\">Arden Dertat</a>, <a href=\"https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\">Link</a> \n",
    "Image by <a href=\"https://towardsdatascience.com/@ardendertat\">Arden Dertat</a>, <a href=\"https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\">Link</a>\n",
    "</div>\n",
    "\n",
    "The three main parameter to watch out in convolutional layer is:\n",
    "\n",
    "- __depth__: The number of filters we'd like to use\n",
    "- __stride__: The size of the step the convolution filter moves each time\n",
    "- __padding__: the size of the zero-padding around the input\n",
    "\n",
    "#### Pooling layer\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*vbfPq-HvBCkAcZhiSTZybg.png\" width=400><br>By <a href=\"https://cs.stanford.edu/people/karpathy/\">Andrej Karpathy</a>, <a href=\"http://cs231n.github.io/convolutional-networks/\">Link</a>\n",
    "\n",
    "Pooling is much more straightforward: It reduces the dimensionality of the input by downsampling it. It defines a window size and an aggregation function to create an approximate output of the input. Using a poolig layer prevents overfitting, reduces the number of weights in the consecutive layers, shortens training time, and also keeps the important informations. The most common aggregation function is __max__.\n",
    "\n",
    "#### Fully-connected layer\n",
    "\n",
    "Regular fully connected layer with proper loss function.\n",
    "\n",
    "#### Further reading:\n",
    "\n",
    "- https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050\n",
    "- http://cs231n.github.io/convolutional-networks/\n",
    "- https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\n",
    "- https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/\n",
    "- https://github.com/ardendertat/Applied-Deep-Learning-with-Keras/blob/master/notebooks/Part%204%20%28GPU%29%20-%20Convolutional%20Neural%20Networks.ipynb\n",
    "\n",
    "---\n",
    "\n",
    "### In Practice\n",
    "\n",
    "#### Build a CNN classifier for the hand digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of cases, width, height, channels (rgb)\n",
    "Xt = X.reshape((X.shape[0], 8, 8, 1))\n",
    "yt = OneHotEncoder(categories='auto').fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Xt, yt, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Xt[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='relu', input_shape=(8, 8, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtrain, ytrain, # training data\n",
    "          batch_size=16,  # number of data points to use in a training round\n",
    "          epochs=100,     # number of full training cycle \n",
    "          validation_data=(Xtest, ytest),  # validation dataset\n",
    "          callbacks=[EarlyStopping(patience=3)])  # function to execute at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(Xtest, ytest)\n",
    "print(f'test loss: {loss}, test acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Build a CNN for the MNIST classification problem\n",
    "\n",
    "In case you stuck in the process, use [this](https://github.com/adventuresinML/adventures-in-ml-code/blob/master/keras_cnn.py) [tutorial]((https://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_x, img_y = 28, 28\n",
    "\n",
    "# load the MNIST data set, which already splits into train and test sets for us\n",
    "(Xtrain, ytrain), (Xtest, ytest) = mnist.load_data()\n",
    "\n",
    "# because the MNIST is greyscale, we only have a single channel\n",
    "Xtrain = Xtrain.reshape()  # TODO: fill in the required shape \n",
    "Xtest = Xtest.reshape()    # TODO: fill in the required shape \n",
    "input_shape = ()           # TODO: fill in the required shape \n",
    "\n",
    "# keras built-in OneHotEncoder solution\n",
    "ytrain = to_categorical(ytrain, num_classes)\n",
    "ytest = to_categorical(ytest, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first image in Xtrain with sns.heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model here\n",
    "model = Sequential([\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
