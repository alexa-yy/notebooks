{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Science\n",
    "## Part III. - Data Transformation\n",
    "\n",
    "### Table of contents\n",
    "- <a href=\"#What-is-Data-Transformation?\">Theory</a>\n",
    "- <a href=\"#1.-Numerical-features\">Numerical features</a>\n",
    "- <a href=\"#2.-Nominal-features\">Nominal features</a>\n",
    "- <a href=\"#3.-FeatureUnions\">Feature Unions</a>\n",
    "\n",
    "## What is Data Transformation?\n",
    "During data transformation the goal is to prepare the data to be usable in the modelling steps. These transformations include normalization, standardization, text processing, generating complex features from basic ones, or any kind of data mapping.\n",
    "\n",
    "_\"...a data transformation converts a set of data values from the data format of a source data system into the data format of a destination data system._\n",
    "\n",
    "_Data transformation can be divided into two steps:_\n",
    "1. _data mapping maps data elements from the source data system to the destination data system and captures any transformation that must occur_\n",
    "2. _code generation that creates the actual transformation program\"_\n",
    "from: <a href=\"https://en.wikipedia.org/wiki/Data_transformation\">Wikipedia</a>\n",
    "\n",
    "### Why is it important?\n",
    "\n",
    "Most of the models are sensitive to data, so you must transform it into a more desired format. Unfortunately the data you start with is usually in terrible shape:\n",
    "\n",
    "- It has missing values\n",
    "- It is full of outliers\n",
    "- The data is distorted by noise\n",
    "- The features are in different scales\n",
    "- The features are correlated/redundant/uninformative\n",
    "\n",
    "\n",
    "### Tools\n",
    "\n",
    "- scaling/binarizing\n",
    "- normalizing/standardizing\n",
    "- outlier detecting\n",
    "- filtering\n",
    "- mathematical transformations\n",
    "- representational changes\n",
    "- etc.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set2val(row, col, val):\n",
    "    if row['tmp']:\n",
    "        row[col] = np.nan\n",
    "    return row\n",
    "\n",
    "def add_missing(df, cols, inf=False, percent=.2):\n",
    "    nrows, _ = df.shape\n",
    "    missing = np.nan if not inf else np.inf\n",
    "    df['tmp'] = np.random.rand(nrows)\n",
    "    df['tmp'] = np.where(df['tmp'] < percent, 1, 0)\n",
    "    df['tgt_col'] = np.random.choice(cols, nrows)\n",
    "    df = df.apply(lambda x: set2val(x, x['tgt_col'], missing), axis=1)\n",
    "    del df['tmp']\n",
    "    del df['tgt_col']\n",
    "    return df\n",
    "\n",
    "def apply_scaler(df, cols, scaler):\n",
    "    df = df.copy()\n",
    "    df[cols] = scaler.transform(df[cols])\n",
    "    return df\n",
    "        \n",
    "def gridplot(X, y=None):\n",
    "    if y is not None:\n",
    "        data = pd.concat((X, y), axis=1)\n",
    "        fig = sns.PairGrid(data, vars=numerical_cols, hue='Label')\n",
    "    else:\n",
    "        fig = sns.PairGrid(X, vars=numerical_cols)\n",
    "    fig = fig.map_diag(plt.hist)\n",
    "    fig = fig.map_offdiag(plt.scatter)\n",
    "    fig = fig.add_legend()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermission - prototype based classifiers\n",
    "\n",
    "### K-Nearest Neighbour classification\n",
    "If it looks like a duck and quacks like a duck, it is probably a duck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('knn', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the loan dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/loan.csv', index_col=0)\n",
    "# Transform target values early for plotting reasons\n",
    "df['Label'] = LabelEncoder().fit_transform(df['Target'].values)\n",
    "\n",
    "# Intentionally left 'Loan_ID' out\n",
    "nominal_cols = ['Gender', 'Married', 'Education',\n",
    "                'Dependents', 'Self_Employed', 'Property_Area']\n",
    "numerical_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "                  'Loan_Amount_Term', 'Credit_History']\n",
    "target_col = ['Label']\n",
    "\n",
    "X = df[numerical_cols + nominal_cols]\n",
    "y = df[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3., random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Numerical features\n",
    "\n",
    "\n",
    "### <a href=\"http://pandas.pydata.org/pandas-docs/stable/missing_data.html\">missing values</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing = add_missing(df, numerical_cols)\n",
    "missing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dropping NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped = missing.dropna(axis=0)\n",
    "dropped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fill NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filled = missing.fillna(value=0)\n",
    "filled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- intepolate NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpolated = missing.interpolate(method='nearest')\n",
    "interpolated.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"http://pandas.pydata.org/pandas-docs/stable/missing_data.html#values-considered-missing\">infinite values</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing = add_missing(df, numerical_cols, inf=True)\n",
    "missing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('mode.use_inf_as_null', True):\n",
    "    print missing.dropna(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('mode.use_inf_as_null', True):\n",
    "    print missing.fillna(value=0).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('mode.use_inf_as_null', True):\n",
    "    print missing.interpolate().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling\">different scales</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train[numerical_cols], y_train)\n",
    "accuracy_score(y_test.values, pipe.predict(X_test[numerical_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaled_pipe = deepcopy(pipe)\n",
    "minmax = MinMaxScaler()\n",
    "scaled_pipe.steps.insert(0, ('minmax', minmax))\n",
    "\n",
    "scaled_pipe.fit(X_train[numerical_cols], y_train)\n",
    "accuracy_score(y_test.values, scaled_pipe.predict(X_test[numerical_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridplot(apply_scaler(X_train, numerical_cols, minmax), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise: Try the same experiment with logistic regression\n",
    "- Create a pipe containing a logistic regressor and measure its accuracy\n",
    "- Create an another pipe with minmaxscaler and logistic regressor. Compare the results and try to explain the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"http://scikit-learn.org/stable/modules/preprocessing.html#normalization\">unnormalized data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_pipe = deepcopy(pipe)\n",
    "standard = StandardScaler()\n",
    "normalized_pipe.steps.insert(0, ('standard', standard))\n",
    "\n",
    "normalized_pipe.fit(X_train[numerical_cols], y_train)\n",
    "accuracy_score(y_test.values, normalized_pipe.predict(X_test[numerical_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridplot(apply_scaler(X_train, numerical_cols, standard), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise: Try the same experiment with logistic regression\n",
    "- Create a pipe containing a logistic regressor and measure its accuracy\n",
    "- Create an another pipe with minmaxscaler and logistic regressor. Compare the results and try to explain the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not now. More about this topic in the next issue of DS101. Cough-cough-<a href=\"http://scikit-learn.org/stable/modules/preprocessing.html#scaling-data-with-outliers\" style=\"color: black; text-decoration: none; cursor: default;\">PCA</a>-cough.\n",
    "\n",
    "### <a href=\"http://scikit-learn.org/stable/modules/preprocessing.html#scaling-data-with-outliers\">outliers</a>\n",
    "\n",
    "<img src=\"https://i0.wp.com/flowingdata.com/wp-content/uploads/2014/09/outlier.gif\" align=\"left\" width=\"400\">\n",
    "\n",
    "<br style=\"clear:left;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "robust_pipe = deepcopy(pipe)\n",
    "robust = RobustScaler()\n",
    "normalized_pipe.steps.insert(0, ('robust', robust))\n",
    "\n",
    "robust_pipe.fit(X_train[numerical_cols], y_train)\n",
    "accuracy_score(y_test.values, robust_pipe.predict(X_test[numerical_cols]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise: Try the same experiment with logistic regression\n",
    "- Create a pipe containing a logistic regressor and measure its accuracy\n",
    "- Create an another pipe with minmaxscaler and logistic regressor. Compare the results and try to explain the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"http://scikit-learn.org/stable/modules/preprocessing.html#feature-binarization\">binarization</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binarizer = Binarizer(threshold=101.0)\n",
    "X_train['BinLoanAmount'] = binarizer.fit_transform(X_train[['LoanAmount']])\n",
    "X_test['BinLoanAmount'] = binarizer.transform(X_test[['LoanAmount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numwithbincols = [col for col in numerical_cols if not col == 'LoanAmount'] + ['BinLoanAmount']\n",
    "pipe.fit(X_train[numwithbincols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test.values, pipe.predict(X_test[numwithbincols]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Intermission II. - Model of the week\n",
    "\n",
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Nominal Features\n",
    "\n",
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "replace_map = {'Dependents': {'0': 0, '1': 1, '2': 2, '3+': 4}}\n",
    "X_train.replace(replace_map).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"\">Label encoding</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64375000000000004"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encodedX_train = X_train[nominal_cols].apply(encoder.fit_transform)\n",
    "encodedX_test = X_test[nominal_cols].apply(encoder.fit_transform)\n",
    "\n",
    "pipe.fit(encodedX_train, y_train)\n",
    "accuracy_score(y_test.values, pipe.predict(encodedX_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features\">One-hot encoding</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label binarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FeatureUnions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    # TODO: add prepocessed features \n",
    "    ('knn', KNeighborsClassifier())    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use binary metric instead of rmse?\n",
    "baseline = np.ones((len(y_train), 1)) * y_train.mean()\n",
    "mean_squared_error(y_train, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "y_hat = pipe.predict(X_test)\n",
    "mean_squared_error(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## : Decision trees\n",
    "\n",
    "__\\# TODO!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
